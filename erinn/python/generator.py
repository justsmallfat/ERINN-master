"""
Data generator for keras model.


References
----------
.. [1] https://github.com/jimmy60504/SeisNN/blob/master/seisnn/tensorflow/generator.py
.. [2] https://medium.com/tensorflow/training-and-serving-ml-models-with-tf-keras-fd975cc0fa27
"""
from __future__ import division, absolute_import, print_function

import warnings
from abc import abstractmethod

import numpy as np
from tensorflow.python.keras.utils import Sequence

from .preprocessing import log_transform, add_noise
from .utils.io_utils import read_pkl


# TODO: deprecate npz support
class BaseGenerator(Sequence):
    """
    Parent class of DataGenerator and PredictGenerator.

    Parameters
    ----------
    file_list : list
        A list of files containing input and target data.
    input_shape : tuple
        The shape of the input layer in the neural network.
    output_shape : tuple, optional
        The shape of the output layer in the neural network.
    batch_size : int, optional
        Size for mini-batch gradient descent.
    shuffle : bool, optional
        Whether to shuffle on the epoch end.
    preprocess : dict, optional


    """
    def __init__(self, file_list, input_shape, output_shape=None, batch_size=32, shuffle=False, **preprocess):
        self.file_list = file_list
        if file_list[0].endswith('npz'):
            warnings.warn('We will no longer support npz converted from matlab,'
                          ' please use pkl generated by python.', FutureWarning)
        self.input_shape = input_shape
        if output_shape is None:
            self.output_shape = input_shape
        else:
            self.output_shape = output_shape
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.indexes = np.arange(len(self.file_list))
        self.preprocess = preprocess
        self.on_epoch_end()

    def __len__(self):
        return int(np.ceil(len(self.file_list) / float(self.batch_size)))

    def __getitem__(self, index):
        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]
        temp_file_list = [self.file_list[k] for k in indexes]
        data = self.get_data(temp_file_list)
        return data

    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.indexes)

    @abstractmethod
    def get_data(self, temp_file_list):
        """
        Extract data from each file.

        Parameters
        ----------
        temp_file_list: list
            List of input data path.

        Returns
        -------
            data

        """
        raise NotImplementedError


class DataGenerator(BaseGenerator):
    """
    Custom Sequence object to train a model on out-of-memory data sets.
    """
    def get_data(self, temp_file_list):
        delta_V = np.empty((len(temp_file_list), *self.input_shape))
        log_rho = np.empty((len(temp_file_list), *self.output_shape))
        for i, file in enumerate(temp_file_list):
            if file.endswith('npz'):
                data = np.load(file)
                delta_V[i, ] = data['Inputs'].reshape(self.input_shape)
                log_rho[i, ] = data['Targets'].reshape(self.output_shape)
            else:
                data = read_pkl(file)
                delta_V[i, ] = data['inputs'].reshape(self.input_shape)
                log_rho[i, ] = data['targets'].reshape(self.output_shape)

        for k, v in self.preprocess.items():
            if k == 'add_noise' and v.get('perform'):
                add_noise(delta_V, **v.get('kwargs'))
            elif k == 'log_transform' and v.get('perform'):
                log_transform(delta_V, **v.get('kwargs'))

        return delta_V, log_rho


class PredictGenerator(DataGenerator):

    def get_data(self, temp_file_list):
        delta_V = np.empty((len(temp_file_list), *self.input_shape))
        for i, file in enumerate(temp_file_list):
            if file.endswith('npz'):
                data = np.load(file)
                delta_V[i, ] = data['Inputs'].reshape(self.input_shape)
            else:
                data = read_pkl(file)
                delta_V[i, ] = data['inputs'].reshape(self.input_shape)

        for k, v in self.preprocess.items():
            if k == 'add_noise' and v.get('perform'):
                add_noise(delta_V, **v.get('kwargs'))
            elif k == 'log_transform' and v.get('perform'):
                log_transform(delta_V, **v.get('kwargs'))

        return delta_V
